---
title: Fondamenti di scheduler
teaching: 45
exercises: 30
---


```{r, echo=FALSE}
# Source the external configuration script
source("load_config.R")
```

::::::::::::::::::::::::::::::::::::::: objectives

- Invia un semplice script al cluster.
- Monitorare l'esecuzione dei lavori utilizzando gli strumenti della riga di comando.
- Ispezionare i file di output e di errore dei lavori.
- Trovare il posto giusto per mettere grandi insiemi di dati sul cluster.

::::::::::::::::::::::::::::::::::::::::::::::::::

:::::::::::::::::::::::::::::::::::::::: questions

- Cos'è uno scheduler e perché un cluster ne ha bisogno?
- Come si lancia un programma da eseguire su un nodo di calcolo del cluster?
- Come posso catturare l'output di un programma eseguito su un nodo del cluster?

::::::::::::::::::::::::::::::::::::::::::::::::::

## Programmatore di lavoro

Un sistema HPC può avere migliaia di nodi e migliaia di utenti. Come si decide chi riceve cosa e quando? Come facciamo a garantire che un task venga eseguito con le risorse di cui ha bisogno? Questo lavoro è gestito da uno speciale software chiamato *scheduler*. In un sistema HPC, lo scheduler gestisce i lavori da eseguire dove e quando.

L'illustrazione seguente paragona i compiti di uno schedulatore di lavori a quelli di un cameriere in un ristorante. Se vi è capitato di dover aspettare un po' in coda per entrare in un ristorante famoso, allora potete capire perché a volte i vostri lavori non partono immediatamente come nel vostro portatile.

![](fig/restaurant_queue_manager.svg){alt="Confronta un job scheduler con un cameriere in un ristorante" max-width="75%"}

Lo scheduler utilizzato in questa lezione è `r config$sched$name`. Sebbene `r config$sched$name` non sia utilizzato ovunque, l'esecuzione dei lavori è abbastanza simile indipendentemente dal software utilizzato. La sintassi esatta può cambiare, ma i concetti rimangono gli stessi.

## Esecuzione di un lavoro batch

L'uso più semplice dello scheduler è quello di eseguire un comando in modo non interattivo. Qualsiasi comando (o serie di comandi) che si desidera eseguire sul cluster è chiamato *lavoro* e il processo di utilizzo dello schedulatore per eseguire il lavoro è chiamato *invio di lavori in batch*.

In questo caso, il lavoro da eseguire è uno script di shell, ovvero un file di testo contenente un elenco di comandi UNIX da eseguire in modo sequenziale. Il nostro script di shell sarà composto da tre parti:

- Alla prima riga, aggiungere ``r config$remote$bash_shebang``. L'opzione `#!` (pronunciata "hash-bang" o "shebang") indica al computer quale programma deve elaborare il contenuto di questo file. In questo caso, gli stiamo dicendo che i comandi che seguono sono scritti per la shell a riga di comando (con cui abbiamo fatto tutto finora).
- in qualsiasi punto sotto la prima riga, aggiungeremo un comando `echo` con un saluto amichevole. Una volta eseguito, lo script di shell stamperà nel terminale qualsiasi cosa venga dopo `echo`.
  - `echo -n` stamperà tutto ciò che segue, *senza* terminare la riga stampando il carattere di nuova riga.
- Nell'ultima riga, invocheremo il comando `hostname`, che stamperà il nome della macchina su cui viene eseguito lo script.

```bash
`r config$remote$prompt` nano example-job.sh
```

```bash
`r config$remote$bash_shebang`

echo -n "This script is running on "
hostname
```

::::::::::::::::::::::::::::::::::::::: challenge

## Creare il nostro lavoro di prova

Eseguire lo script. Viene eseguito sul cluster o solo sul nostro nodo di accesso?

::::::::::::::: solution

## Soluzione

```bash
`r config$remote$prompt` bash example-job.sh
```

```output
This script is running on `r config$remote$host`
```

:::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::::::::::::::::

Questo script è stato eseguito sul nodo di login, ma vogliamo sfruttare i nodi di calcolo: abbiamo bisogno che lo scheduler metta in coda `example-job.sh` per eseguirlo su un nodo di calcolo.

Per inviare questo task allo scheduler, si usa il comando ``r config$sched$submit$name``. Questo crea un *lavoro* che eseguirà il *script* quando verrà *spedito* a un nodo di calcolo che il sistema di accodamento ha identificato come disponibile per eseguire il lavoro.

```bash
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
```

```{r, child=paste(snippets, '/scheduler/basic-job-script.Rmd', sep=''), eval=TRUE}

```

E questo è tutto ciò che dobbiamo fare per inviare un lavoro. Il nostro lavoro è finito: ora lo scheduler prende il sopravvento e cerca di eseguire il lavoro per noi. Mentre il lavoro è in attesa di essere eseguito, viene inserito in un elenco di lavori chiamato *queue*. Per verificare lo stato del nostro lavoro, controlliamo la coda usando il comando ``r config$sched$status` `r config$sched$flag$user``.

```bash
`r config$remote$prompt` `r config$sched$status` `r config$sched$flag$user`
```

```output
JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
    9 cpubase_b example-   user01  R       0:05      1 node1
```

Possiamo vedere tutti i dettagli del nostro lavoro, soprattutto che è nello stato `R` o `RUNNING`. A volte i nostri lavori potrebbero dover aspettare in coda (`PENDING`) o avere un errore (`E`).

:::::::::::::::::::::::::::::::::::::: discussion

## Dov'è l'output?

Nel nodo di accesso, questo script stampava l'output nel terminale, ma ora, quando ``r config$sched$status`` mostra che il lavoro è terminato, non viene stampato nulla nel terminale.

L'output del lavoro del cluster viene solitamente reindirizzato a un file nella directory da cui è stato lanciato. Usare `ls` per trovare e `cat` per leggere il file.

::::::::::::::::::::::::::::::::::::::::::::::::::

## Personalizzazione di un lavoro

Il lavoro appena eseguito ha utilizzato tutte le opzioni predefinite dello schedulatore. In uno scenario reale, probabilmente non è quello che vogliamo. Le opzioni predefinite rappresentano un minimo ragionevole. È probabile che avremo bisogno di più core, più memoria, più tempo e altre considerazioni speciali. Per avere accesso a queste risorse, dobbiamo personalizzare il nostro script di lavoro.

I commenti negli script di shell UNIX (indicati con `#`) sono generalmente ignorati, ma ci sono delle eccezioni. Per esempio, il commento speciale `#!` all'inizio degli script specifica quale programma deve essere usato per eseguirli (di solito si vede ``r config$local$bash_shebang``). Anche gli schedulatori, come `r config$sched$name`, hanno un commento speciale usato per indicare opzioni specifiche dello schedulatore. Sebbene questi commenti differiscano da schedulatore a schedulatore, il commento speciale di `r config$sched$name` è ``r config$sched$comment``. Tutto ciò che segue il commento ``r config$sched$comment`` viene interpretato come un'istruzione per lo schedulatore.

Illustriamo questo esempio. Per impostazione predefinita, il nome di un lavoro è il nome dello script, ma l'opzione ``r config$sched$flag$name`` può essere usata per cambiare il nome di un lavoro. Aggiungere un'opzione allo script:

```bash
`r config$remote$prompt` cat example-job.sh
```

```bash
`r config$remote$bash_shebang`
`r config$sched$comment` `r config$sched$flag$name` hello-world

echo -n "This script is running on "
hostname
```

Inviare il lavoro e monitorarne lo stato:

```bash
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
`r config$remote$prompt` `r config$sched$status` `r config$sched$flag$user`
```

```output
JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
   10 cpubase_b hello-wo   user01  R       0:02      1 node1
```

Fantastico, abbiamo cambiato con successo il nome del nostro lavoro!

### Richieste di risorse

Che dire di cambiamenti più importanti, come il numero di core e di memoria per i nostri lavori? Una cosa assolutamente fondamentale quando si lavora su un sistema HPC è specificare le risorse necessarie per eseguire un lavoro. Questo permette allo scheduler di trovare il momento e il posto giusto per programmare il nostro lavoro. Se non si specificano i requisiti (ad esempio la quantità di tempo necessaria), è probabile che si rimanga bloccati con le risorse predefinite del sito, il che probabilmente non è ciò che si desidera.

Le seguenti sono diverse richieste di risorse chiave:

- `--ntasks=<ntasks>` o `-n <ntasks>`: Di quanti core di CPU ha bisogno il vostro lavoro, in totale?

- `--time <days-hours:minutes:seconds>` o `-t <days-hours:minutes:seconds>`: Quanto tempo reale (walltime) impiegherà il lavoro per essere eseguito? La parte `<days>` può essere omessa.

- `--mem=<megabytes>`: Di quanta memoria su un nodo ha bisogno il lavoro in megabyte? Si possono anche specificare i gigabyte aggiungendo una piccola "g" dopo (esempio: `--mem=5g`)

- `--nodes=<nnodes>` o `-N <nnodes>`: Su quante macchine separate deve essere eseguito il lavoro? Si noti che se si imposta `ntasks` su un numero superiore a quello che può offrire una sola macchina, `r config$sched$name` imposterà automaticamente questo valore.

Si noti che il solo fatto di *richiedere* queste risorse non rende il lavoro più veloce, né significa necessariamente che si consumeranno tutte queste risorse. Significa solo che vengono messe a disposizione. Il lavoro può finire per utilizzare meno memoria, meno tempo o meno nodi di quelli richiesti, ma verrà comunque eseguito.

È meglio che le richieste riflettano accuratamente i requisiti del lavoro. In una puntata successiva di questa lezione parleremo di come assicurarsi di utilizzare le risorse in modo efficace.

::::::::::::::::::::::::::::::::::::::: challenge

## Invio di richieste di risorse

Modificare il nostro script `hostname` in modo che venga eseguito per un minuto, quindi inviare un lavoro per esso sul cluster.

::::::::::::::: solution

## Soluzione

```bash
`r config$remote$prompt` cat example-job.sh
```

```bash
`r config$remote$bash_shebang`
`r config$sched$comment` `r config$sched$flag$time` 00:01 # timeout in HH:MM

echo -n "This script is running on "
sleep 20 # time in seconds
hostname
```

```bash
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
```

Perché il tempo di esecuzione `r config$sched$name` e il tempo `sleep` non sono identici?



:::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::::::::::::::::

Le richieste di risorse sono in genere vincolanti. Se si superano, il lavoro viene eliminato. Utilizziamo il tempo di parete come esempio. Richiederemo 1 minuto di tempo di parete e cercheremo di eseguire un lavoro per due minuti.

```bash
`r config$remote$prompt` cat example-job.sh
```

```bash
`r config$remote$bash_shebang`
`r config$sched$comment` `r config$sched$flag$name` long_job
`r config$sched$comment` `r config$sched$flag$time` 00:01 # timeout in HH:MM

echo "This script is running on ... "
sleep 240 # time in seconds
hostname
```

Inviare il lavoro e attendere che finisca. Una volta terminato, controllare il file di log.

```bash
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
`r config$remote$prompt` `r config$sched$status` `r config$sched$flag$user`
```

```bash
`r config$remote$prompt` cat slurm-12.out
```

```output
This script is running on ...
slurmstepd: error: *** JOB 12 ON node1 CANCELLED AT 2021-02-19T13:55:57
DUE TO TIME LIMIT ***
```

Il nostro lavoro è stato annullato per aver superato la quantità di risorse richieste. Anche se questo sembra un problema, in realtà si tratta di una caratteristica. Il rispetto rigoroso delle richieste di risorse consente allo scheduler di trovare il miglior posto possibile per i lavori. Ancora più importante, garantisce che un altro utente non possa utilizzare più risorse di quelle che gli sono state assegnate. Se un altro utente sbaglia e tenta accidentalmente di usare tutti i core o la memoria di un nodo, `r config$sched$name` limiterà il suo lavoro alle risorse richieste o lo ucciderà del tutto. Gli altri lavori sul nodo non ne risentiranno. Ciò significa che un utente non può rovinare l'esperienza degli altri: gli unici lavori interessati da un errore di programmazione saranno i propri.

## Annullamento di un lavoro

A volte capita di commettere un errore e di dover cancellare un lavoro. Questo può essere fatto con il comando ``r config$sched$del``. Inviamo un lavoro e poi annulliamolo usando il suo numero di lavoro (ricordate di cambiare il tempo di esecuzione in modo che funzioni abbastanza a lungo da permettervi di annullarlo prima che venga ucciso).

```bash
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
`r config$remote$prompt` `r config$sched$status` `r config$sched$flag$user`
```

```output
Submitted batch job 13

JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
   13 cpubase_b long_job   user01  R       0:02      1 node1
```

Ora annullate il lavoro con il suo numero (stampato nel terminale). Un ritorno pulito del prompt dei comandi indica che la richiesta di annullamento del lavoro è andata a buon fine.

```bash
`r config$remote$prompt` `r config$sched$del` 38759
# It might take a minute for the job to disappear from the queue...
`r config$remote$prompt` `r config$sched$status` `r config$sched$flag$user`
```

```output
JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)
```

::::::::::::::::::::::::::::::::::::::: challenge

## Annullamento di lavori multipli

È anche possibile cancellare tutti i lavori in una volta sola usando l'opzione `-u`. In questo modo si cancellano tutti i lavori di un utente specifico (in questo caso, l'utente stesso). Si noti che è possibile cancellare solo i propri lavori.

Provare a inviare più lavori e poi annullarli tutti.

::::::::::::::: solution

## Soluzione

Per prima cosa, inviare un trio di lavori:

```bash
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
`r config$remote$prompt` `r config$sched$submit$name` `r config$sched$submit$options` example-job.sh
```

Poi, annullarli tutti:

```bash
`r config$remote$prompt` `r config$sched$del` -u `r config$remote$user`
```

:::::::::::::::::::::::::

::::::::::::::::::::::::::::::::::::::::::::::::::

## Altri tipi di lavoro

Finora ci siamo concentrati sull'esecuzione di lavori in modalità batch. ``r config$sched$name`` offre anche la possibilità di avviare una sessione interattiva.

Molto spesso ci sono compiti che devono essere eseguiti in modo interattivo. Creare un intero script di lavoro potrebbe essere eccessivo, ma la quantità di risorse richieste è troppo elevata per essere gestita da un nodo di login. Un buon esempio potrebbe essere la creazione di un indice del genoma per l'allineamento con uno strumento come [HISAT2][hisat]. Fortunatamente, è possibile eseguire questo tipo di compiti una tantum con ``r config$sched$interactive``.

``r config$sched$interactive`` esegue un singolo comando sul cluster e poi esce. Dimostriamo questo eseguendo il comando `hostname` con ``r config$sched$interactive``. (È possibile annullare un lavoro ``r config$sched$interactive`` con ``Ctrl-c``)

```bash
`r config$remote$prompt` `r config$sched$interactive` hostname
```

```output
`r config$remote$node`
```

``r config$sched$interactive`` accetta tutte le stesse opzioni di ``r config$sched$submit$name``. Tuttavia, invece di specificarle in uno script, queste opzioni vengono specificate sulla riga di comando quando si avvia un lavoro. Per inviare un lavoro che utilizza 2 CPU, ad esempio, si può usare il seguente comando:

```bash
`r config$remote$prompt` `r config$sched$interactive` -n 2 echo "This job will use 2 CPUs."
```

```output
This job will use 2 CPUs.
This job will use 2 CPUs.
```

In genere, l'ambiente di shell risultante sarà lo stesso di quello di ``r config$sched$submit$name``.

### Lavori interattivi

A volte si ha bisogno di molte risorse per l'uso interattivo. Forse è la prima volta che si esegue un'analisi o si sta cercando di eseguire il debug di qualcosa che è andato storto con un lavoro precedente. Fortunatamente, `r config$sched$name` semplifica l'avvio di un lavoro interattivo con ``r config$sched$interactive``:

```bash
`r config$remote$prompt` `r config$sched$interactive` --pty bash
```

Dovrebbe apparire un prompt di bash. Si noti che il prompt probabilmente cambierà per riflettere la nuova posizione, in questo caso il nodo di calcolo su cui si è effettuato l'accesso. Si può anche verificare con `hostname`.

::::::::::::::::::::::::::::::::::::::::: callout

## Creazione della grafica remota

Per vedere l'output grafico dei lavori, è necessario utilizzare l'inoltro X11. Per connettersi con questa funzione abilitata, usare l'opzione `-Y` quando si effettua il login con il comando `ssh`, ad esempio, `ssh -Y `r config$remote$user`@`r config$remote$login``.

Per dimostrare cosa succede quando si crea una finestra grafica sul nodo remoto, usare il comando `xeyes`. Dovrebbe apparire un paio di occhi relativamente adorabili (premere `Ctrl-C` per fermarsi). Se si utilizza un Mac, è necessario aver installato XQuartz (e riavviato il computer) perché questo funzioni.

Se nel cluster è installato il plugin [slurm-spank-x11](https://github.com/hautreux/slurm-spank-x11), si può garantire l'inoltro X11 nei lavori interattivi usando l'opzione `--x11` per ``r config$sched$interactive`` con il comando ``r config$sched$interactive` --x11 --pty bash`.

::::::::::::::::::::::::::::::::::::::::::::::::::

Al termine del lavoro interattivo, digitare `exit` per uscire dalla sessione.

[hisat]: https://daehwankimlab.github.io/hisat2/

:::::::::::::::::::::::::::::::::::::::: keypoints

- Lo scheduler gestisce la condivisione delle risorse di calcolo tra gli utenti.
- Un lavoro è solo uno script di shell.
- Richiedere *poco* più risorse di quelle necessarie.

::::::::::::::::::::::::::::::::::::::::::::::::::



